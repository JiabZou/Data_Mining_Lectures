{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming anomaly detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection is a very common ML task. Here we will consider streaming tabular data.\n",
    "\n",
    "## Streaming a dataset\n",
    "\n",
    "As an example, we'll use a credit card transactions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit card frauds.\n",
       "\n",
       "The datasets contains transactions made by credit cards in September 2013 by european\n",
       "cardholders. This dataset presents transactions that occurred in two days, where we have 492\n",
       "frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class\n",
       "(frauds) account for 0.172% of all transactions.\n",
       "\n",
       "It contains only numerical input variables which are the result of a PCA transformation.\n",
       "Unfortunately, due to confidentiality issues, we cannot provide the original features and more\n",
       "background information about the data. Features V1, V2, ... V28 are the principal components\n",
       "obtained with PCA, the only features which have not been transformed with PCA are 'Time' and\n",
       "'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first\n",
       "transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be\n",
       "used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and\n",
       "it takes value 1 in case of fraud and 0 otherwise.\n",
       "\n",
       "      Name  CreditCard                                                     \n",
       "      Task  Binary classification                                          \n",
       "   Samples  284,807                                                        \n",
       "  Features  30                                                             \n",
       "    Sparse  False                                                          \n",
       "      Path  /Users/max/river_data/CreditCard/creditcard.csv                \n",
       "       URL  https://maxhalford.github.io/files/datasets/creditcardfraud.zip\n",
       "      Size  143.84 MB                                                      \n",
       "Downloaded  True                                                           "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = datasets.CreditCard()\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question ðŸ¤”: in production, what would be the output of an anomaly detector on this dataset?**\n",
    "\n",
    "**Question ðŸ¤”: how would humans and the model interact with each other?**\n",
    "\n",
    "**Question ðŸ¤”: how could you exploit human feedback?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "river.datasets.credit_card.CreditCard"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is special in that it isn't loaded in memory. When you loop over it with `for`, it will stream the dataset from the disk, one row at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 0.0,\n",
       " 'V1': -1.3598071336738,\n",
       " 'V2': -0.0727811733098497,\n",
       " 'V3': 2.53634673796914,\n",
       " 'V4': 1.37815522427443,\n",
       " 'V5': -0.338320769942518,\n",
       " 'V6': 0.462387777762292,\n",
       " 'V7': 0.239598554061257,\n",
       " 'V8': 0.0986979012610507,\n",
       " 'V9': 0.363786969611213,\n",
       " 'V10': 0.0907941719789316,\n",
       " 'V11': -0.551599533260813,\n",
       " 'V12': -0.617800855762348,\n",
       " 'V13': -0.991389847235408,\n",
       " 'V14': -0.311169353699879,\n",
       " 'V15': 1.46817697209427,\n",
       " 'V16': -0.470400525259478,\n",
       " 'V17': 0.207971241929242,\n",
       " 'V18': 0.0257905801985591,\n",
       " 'V19': 0.403992960255733,\n",
       " 'V20': 0.251412098239705,\n",
       " 'V21': -0.018306777944153,\n",
       " 'V22': 0.277837575558899,\n",
       " 'V23': -0.110473910188767,\n",
       " 'V24': 0.0669280749146731,\n",
       " 'V25': 0.128539358273528,\n",
       " 'V26': -0.189114843888824,\n",
       " 'V27': 0.133558376740387,\n",
       " 'V28': -0.0210530534538215,\n",
       " 'Amount': 149.62}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for transaction, is_fraud in dataset.take(1):\n",
    "    ...\n",
    "\n",
    "transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_fraud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question ðŸ¤”: what is the fraud rate?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progressive validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROCAUC: 91.49%"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    anomaly.HalfSpaceTrees(seed=42)\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "for x, y in dataset.take(100_000):\n",
    "    score = model.score_one(x)\n",
    "    model = model.learn_one(x)\n",
    "    metric = metric.update(y, score)\n",
    "\n",
    "metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question ðŸ¤”: what do you think of this way of evaluating a model?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, an anomaly detection task is tackled with an unsupervised model due to a lack of labels. Here, we have labels, which allows to evaluate the model's performance. However, we can also train a supervised model and see if it performs any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROCAUC: 89.20%"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "for x, y in dataset.take(100_000):\n",
    "    score = model.predict_proba_one(x)[True]\n",
    "    model = model.learn_one(x, y)\n",
    "    metric = metric.update(y, score)\n",
    "\n",
    "metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question ðŸ¤”: why do you think the performance is worse?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "River also has an `evaluate` module with a `progressive_val_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,000] ROCAUC: 94.57% â€“ 00:00:00 â€“ 10.3 KB\n",
      "[20,000] ROCAUC: 89.21% â€“ 00:00:01 â€“ 10.3 KB\n",
      "[30,000] ROCAUC: 87.08% â€“ 00:00:01 â€“ 10.3 KB\n",
      "[40,000] ROCAUC: 87.39% â€“ 00:00:02 â€“ 10.3 KB\n",
      "[50,000] ROCAUC: 90.46% â€“ 00:00:03 â€“ 10.3 KB\n",
      "[60,000] ROCAUC: 89.19% â€“ 00:00:03 â€“ 10.3 KB\n",
      "[70,000] ROCAUC: 89.08% â€“ 00:00:04 â€“ 10.3 KB\n",
      "[80,000] ROCAUC: 89.23% â€“ 00:00:05 â€“ 10.3 KB\n",
      "[90,000] ROCAUC: 89.76% â€“ 00:00:05 â€“ 10.3 KB\n",
      "[100,000] ROCAUC: 89.20% â€“ 00:00:06 â€“ 10.3 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 89.20%"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import evaluate\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset.take(100_000),\n",
    "    model=compose.Pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        linear_model.LogisticRegression()\n",
    "    ),\n",
    "    metric=metrics.ROCAUC(),\n",
    "    print_every=10_000,\n",
    "    show_time=True,\n",
    "    show_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the supervised approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an anomaly detection task, the number of positive cases is usually much lower than the amount of negatives. This penalizes many supervised classification models, because many are based on the assumption that the data is somewhat balanced. In the case of logistic regression, it's possible to adjust the loss function to increase the importance of positive samples on the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,000] ROCAUC: 95.90% â€“ 00:00:00 â€“ 10.26 KB\n",
      "[20,000] ROCAUC: 92.71% â€“ 00:00:01 â€“ 10.26 KB\n",
      "[30,000] ROCAUC: 91.84% â€“ 00:00:01 â€“ 10.26 KB\n",
      "[40,000] ROCAUC: 92.17% â€“ 00:00:02 â€“ 10.26 KB\n",
      "[50,000] ROCAUC: 94.16% â€“ 00:00:03 â€“ 10.26 KB\n",
      "[60,000] ROCAUC: 92.55% â€“ 00:00:03 â€“ 10.26 KB\n",
      "[70,000] ROCAUC: 92.21% â€“ 00:00:04 â€“ 10.26 KB\n",
      "[80,000] ROCAUC: 92.28% â€“ 00:00:05 â€“ 10.26 KB\n",
      "[90,000] ROCAUC: 92.59% â€“ 00:00:06 â€“ 10.26 KB\n",
      "[100,000] ROCAUC: 91.87% â€“ 00:00:06 â€“ 10.26 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 91.87%"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import optim\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset.take(100_000),\n",
    "    model=compose.Pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        linear_model.LogisticRegression(\n",
    "            loss=optim.losses.Log(weight_pos=5)\n",
    "        )\n",
    "    ),\n",
    "    metric=metrics.ROCAUC(),\n",
    "    print_every=10_000,\n",
    "    show_time=True,\n",
    "    show_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to under-sample the majority class. The idea is that the model is being drowned with negative examples. Adjusting the class distribution can help a model. Note that one could also over-sample the minority class. However, the advantage of under-sampling is that it reduces the processing time, because less data has to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,000] ROCAUC: 94.55% â€“ 00:00:00 â€“ 14.33 KB\n",
      "[20,000] ROCAUC: 95.59% â€“ 00:00:01 â€“ 14.33 KB\n",
      "[30,000] ROCAUC: 95.40% â€“ 00:00:01 â€“ 14.33 KB\n",
      "[40,000] ROCAUC: 95.34% â€“ 00:00:02 â€“ 14.33 KB\n",
      "[50,000] ROCAUC: 96.72% â€“ 00:00:02 â€“ 14.33 KB\n",
      "[60,000] ROCAUC: 95.42% â€“ 00:00:03 â€“ 14.33 KB\n",
      "[70,000] ROCAUC: 95.14% â€“ 00:00:03 â€“ 14.33 KB\n",
      "[80,000] ROCAUC: 95.38% â€“ 00:00:04 â€“ 14.33 KB\n",
      "[90,000] ROCAUC: 95.72% â€“ 00:00:05 â€“ 14.33 KB\n",
      "[100,000] ROCAUC: 95.26% â€“ 00:00:05 â€“ 14.33 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 95.26%"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import imblearn\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset.take(100_000),\n",
    "    model=compose.Pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        imblearn.RandomUnderSampler(\n",
    "            classifier=linear_model.LogisticRegression(),\n",
    "            desired_dist={0: .8, 1: .2},\n",
    "            seed=42\n",
    "        )\n",
    "    ),\n",
    "    metric=metrics.ROCAUC(),\n",
    "    print_every=10_000,\n",
    "    show_time=True,\n",
    "    show_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing prevents us from combining the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,000] ROCAUC: 94.23% â€“ 00:00:00 â€“ 14.28 KB\n",
      "[20,000] ROCAUC: 96.77% â€“ 00:00:01 â€“ 14.28 KB\n",
      "[30,000] ROCAUC: 96.86% â€“ 00:00:01 â€“ 14.28 KB\n",
      "[40,000] ROCAUC: 96.54% â€“ 00:00:02 â€“ 14.28 KB\n",
      "[50,000] ROCAUC: 97.54% â€“ 00:00:02 â€“ 14.28 KB\n",
      "[60,000] ROCAUC: 97.15% â€“ 00:00:03 â€“ 14.28 KB\n",
      "[70,000] ROCAUC: 96.83% â€“ 00:00:03 â€“ 14.28 KB\n",
      "[80,000] ROCAUC: 96.77% â€“ 00:00:04 â€“ 14.28 KB\n",
      "[90,000] ROCAUC: 96.97% â€“ 00:00:05 â€“ 14.28 KB\n",
      "[100,000] ROCAUC: 96.49% â€“ 00:00:05 â€“ 14.28 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 96.49%"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import imblearn\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset.take(100_000),\n",
    "    model=compose.Pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        imblearn.RandomUnderSampler(\n",
    "            classifier=linear_model.LogisticRegression(\n",
    "                loss=optim.losses.Log(weight_pos=5)\n",
    "            ),\n",
    "            desired_dist={0: .8, 1: .2},\n",
    "            seed=42\n",
    "        )\n",
    "    ),\n",
    "    metric=metrics.ROCAUC(),\n",
    "    print_every=10_000,\n",
    "    show_time=True,\n",
    "    show_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further: active learning\n",
    "\n",
    "We started off with an unsupervised approach. We did so because we assumed we had no labels to train a supervised model. Next, we trained a supervised model, which performed with some tuning. In a real setup, labels wouldn't be available at first. One way to proceed would be to have both models running alongside. \n",
    "\n",
    "The first model would be unsupervised and rank samples according to their anomaly score. Humans would label the samples according to this ranking. These labels would then feed into the second model. A great way to prioritize this labelling effort is to use active learning. See a demo [here](https://next.databutton.com/v/13lkg6b6), with explanations [here](https://maxhalford.github.io/blog/online-active-learning-river-databutton/).\n",
    "\n",
    "**Question ðŸ¤”: if there are two models running alongside, how to determine which one's outputs should be used?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55fbbcf542e06cc59ad76a1e0d5dc36ee204d6d2b704491656ee6b3487310122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
