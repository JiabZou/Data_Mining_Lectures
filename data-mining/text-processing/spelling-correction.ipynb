{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is adapted from Peter Norvig's [post](http://norvig.com/spell-correct.html) on spelling correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "big = requests.get('http://norvig.com/big.txt').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of The Adventures of Sherlock Holmes\n",
      "by Sir Arthur Conan Doyle\n",
      "(#15 in our series by Sir Arthur Conan Doyle)\n",
      "\n",
      "Copyright laws are changing all over the world. Be sure to check the\n",
      "copyright laws for your country before downloading or redistributing\n",
      "this or any other Project Gutenberg eBook.\n",
      "\n",
      "This header should be the first thing seen when viewing this Project\n",
      "Gutenberg file.  Please do not remove it.  Do not change or edit the\n",
      "header without written permission.\n",
      "\n",
      "Please read the \"legal small print,\" and other information about the\n",
      "eBook and Project Gutenberg at the bottom of this file.  Included is\n",
      "important information about your specific rights and restrictions in\n",
      "how the file may be used.  You can also find out about how to make a\n",
      "donation to Project Gutenberg, and how to get involved.\n",
      "\n",
      "\n",
      "**Welcome To The World of Free Plain Vanilla Electronic Texts**\n",
      "\n",
      "**eBooks Readable By Both Humans and By Computers, Since 1971**\n",
      "\n",
      "*****These eBooks Were Prepared By Thousan\n"
     ]
    }
   ],
   "source": [
    "print(big[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(big))\n",
    "\n",
    "def correct(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def P(word, N=sum(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of spelling correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spelling'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('speling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corrected'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('korrectud')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this work? Well, the first idea to generate candidates. We can do this by generating all possible words that are one edit away from the original word. We then filter these candidates by only keeping the ones that are in our vocabulary. Next, we rank these candidates by some score. In this case, the score is frequency of the word. We then pick the candidate with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canda',\n",
       " 'cnadl',\n",
       " 'candjl',\n",
       " 'candzl',\n",
       " 'candls',\n",
       " 'candln',\n",
       " 'canfl',\n",
       " 'lcandl',\n",
       " 'cacndl',\n",
       " 'cabndl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choices(list(edits1('candl')), k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also consider words that are two edits away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caandil',\n",
       " 'caazdl',\n",
       " 'vaqndl',\n",
       " 'candlfy',\n",
       " 'calndm',\n",
       " 'caqndd',\n",
       " 'cagdl',\n",
       " 'cawdo',\n",
       " 'cacbdl',\n",
       " 'canldla']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(list(edits2('candl')), k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `candidates` function lists all the 1-edits and 2-edits, and filter those that are not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'canal', 'candle', 'candy'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('candl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, there's three of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candy 8.963906829152417e-07\n",
      "canal 6.454012916989741e-05\n",
      "candle 3.2270064584948705e-05\n"
     ]
    }
   ],
   "source": [
    "for candidate in candidates('candl'):\n",
    "    print(candidate, P(candidate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canal'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('candl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is actually a simple Bayes classifier. We want to find the most probable correction given a word. We can do this by using Bayes rule:\n",
    "\n",
    "$$argmax_{c \\in candidates} P(c|w) = \\frac{P(c)P(w|c)}{P(w)}$$\n",
    "\n",
    "We can ignore the denominator since it's the same for all candidates. So we can simplify this to:\n",
    "\n",
    "$$argmax_{c \\in candidates} P(c)P(w|c)$$\n",
    "\n",
    "This basic model estimates $P(c)$ by the frequency of the word in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.15%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{P('the'):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $P(w|c)$ is more complicated. It's the likelihood of observing a typo. The thing is, we don't really have access to a list of typos people made. So our basic model simply says that a 1-edit is more likely than a 2-edit. A more sophisticated model would use a corpus of misspellings to learn typical typos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings/For_machines'\n",
    "\n",
    "content = requests.get(url).content.decode()\n",
    "soup = BeautifulSoup(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,156 words\n",
      "4,291 misspellings\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "typos = defaultdict(list)\n",
    "\n",
    "for line in soup.find(name='pre').text.splitlines():\n",
    "    typo, correction = line.split('->')\n",
    "    typos[correction].append(typo)\n",
    "\n",
    "typos = dict(typos)\n",
    "\n",
    "print(f'{len(typos):,d} words')\n",
    "print(f'{sum(map(len, typos.values())):,d} misspellings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ consituted -> constituted == constituted\n",
      "❌ tast -> last != taste\n",
      "✅ appearences -> appearances == appearances\n",
      "✅ apperances -> appearances == appearances\n",
      "✅ appereances -> appearances == appearances\n",
      "❌ Pucini -> mucin != Puccini\n",
      "❌ rechargable -> rechargable != rechargeable\n",
      "✅ casette -> cassette == cassette\n",
      "✅ verisons -> versions == versions\n",
      "✅ nowe -> now == now\n",
      "❌ regardes -> regarded != regards\n",
      "✅ mataphysical -> metaphysical == metaphysical\n",
      "✅ coform -> conform == conform\n",
      "❌ shoudln -> shouldn != should, shouldn't\n",
      "❌ homogeneize -> homogeneize != homogenize\n",
      "✅ guerrila -> guerrilla == guerrilla\n",
      "❌ implimented -> complimented != implemented\n",
      "✅ threee -> three == three\n",
      "✅ inocence -> innocence == innocence\n",
      "❌ maneouvres -> maneuvers != manoeuvres\n",
      "❌ deteoriated -> deteoriated != deteriorated\n",
      "❌ scoll -> scold != scroll\n",
      "❌ Malcom -> falcon != Malcolm\n",
      "✅ buisness -> business == business\n",
      "✅ busines -> business == business\n",
      "✅ busness -> business == business\n",
      "✅ bussiness -> business == business\n",
      "❌ omniverously -> omniverously != omnivorously\n",
      "✅ soudns -> sounds == sounds\n",
      "❌ souveniers -> souvenir != souvenirs\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "keys = random.sample(list(typos.keys()), 25)\n",
    "\n",
    "for truth in keys:\n",
    "    misspellings = typos[truth]\n",
    "    for misspelling in misspellings:\n",
    "        correction = correct(misspelling)\n",
    "        if correction == truth:\n",
    "            print(f'✅ {misspelling} -> {correction} == {truth}')\n",
    "        else:\n",
    "            print(f'❌ {misspelling} -> {correction} != {truth}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
