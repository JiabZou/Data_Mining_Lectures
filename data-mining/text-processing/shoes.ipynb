{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing shoe compositions\n",
    "\n",
    "The goal of this notebook is to look at some practical NLP code, understand the concept of caching, and get familiar with working with JSON objects. We'll be using the data provided in [this](https://maxhalford.github.io/blog/carbonfact-nlp-open-problem/) blog post.\n",
    "\n",
    "## The data\n",
    "\n",
    "Let's start looking at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "inputs = pathlib.Path('shoes/inputs.txt').read_text().splitlines()\n",
    "len(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "outputs = json.loads(pathlib.Path('shoes/outputs.json').read_text())\n",
    "len(outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a little script to print out a random sample. This will help us in getting familiar with the parsing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è INPUT\n",
      "\n",
      "52%polyamide,39%cotton,9%elastane\n",
      "\n",
      "‚¨ÜÔ∏è OUTPUT\n",
      "\n",
      "{\n",
      "    \"\": [\n",
      "        {\n",
      "            \"material\": \"polyamide\",\n",
      "            \"proportion\": 52.0\n",
      "        },\n",
      "        {\n",
      "            \"material\": \"cotton\",\n",
      "            \"proportion\": 39.0\n",
      "        },\n",
      "        {\n",
      "            \"material\": \"elastane\",\n",
      "            \"proportion\": 9.0\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "i = random.randint(0, len(inputs))\n",
    "print(\"‚¨áÔ∏è INPUT\")\n",
    "print()\n",
    "print(inputs[i])\n",
    "print()\n",
    "print(\"‚¨ÜÔ∏è OUTPUT\")\n",
    "print()\n",
    "print(json.dumps(outputs[i], indent=4, sort_keys=True))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first parser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to write a first parser. We'll be using the [`regex` library](https://github.com/mrabarnett/mrab-regex), which is not part of the standard library. You'll have to install it:\n",
    "\n",
    "```sh\n",
    "pip install regex\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def named_pattern(name, pattern):\n",
    "    return f\"(?P<{name}>{pattern})\"\n",
    "\n",
    "\n",
    "def many(pattern, at_least_one=True):\n",
    "    return f\"({pattern})+\" if at_least_one else f\"({pattern})*\"\n",
    "\n",
    "\n",
    "def sep(pattern, sep):\n",
    "    return pattern + many(sep + pattern, at_least_one=False)\n",
    "\n",
    "\n",
    "def split_composition_into_components(text):\n",
    "    \"\"\"\n",
    "\n",
    "    >>> split_composition_into_components(\"Upper: 80% Leather, 20% Textile\")\n",
    "    {'Upper': '80% Leather, 20% Textile'}\n",
    "\n",
    "    \"\"\"\n",
    "    component = \"\"\n",
    "    materials = []\n",
    "    component_materials = {}\n",
    "\n",
    "    for token in regex.split(r\"\\s+\", text):\n",
    "        if token.endswith(\":\"):\n",
    "            if materials:\n",
    "                component_materials[component] = \" \".join(materials)\n",
    "                materials = []\n",
    "            component = token.rstrip(\":\")\n",
    "        else:\n",
    "            materials.append(token)\n",
    "    else:\n",
    "        if materials:\n",
    "            component_materials[component] = \" \".join(materials)\n",
    "\n",
    "    return component_materials\n",
    "\n",
    "\n",
    "def parse_materials(text):\n",
    "    \"\"\"\n",
    "\n",
    "    >>> parse_materials(\"80% Leather 20% Textile\")\n",
    "    [{'material': 'Leather', 'proportion': 80.0}, {'material': 'Textile', 'proportion': 20.0}]\n",
    "\n",
    "    \"\"\"\n",
    "    material_pat = named_pattern(\"material\", r\"[a-zA-Z√Ä-√ø\\-\\s']+[a-zA-Z√Ä-√ø\\-']\")\n",
    "    proportion_pat = named_pattern(\"proportion\", r\"\\d{1,3}([,\\.]\\d{1,2})?\") + \"%?\"\n",
    "\n",
    "    pattern = sep(rf\"{proportion_pat}\\s*{material_pat}\", \" \")\n",
    "    match = regex.match(pattern, text)\n",
    "\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"material\": m,\n",
    "            \"proportion\": float(p)\n",
    "        }\n",
    "        for m, p in zip(\n",
    "            match.capturesdict()[\"material\"],\n",
    "            match.capturesdict()[\"proportion\"],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_composition(text):\n",
    "    component_materials = split_composition_into_components(text)\n",
    "    return {\n",
    "        component: parse_materials(materials)\n",
    "        for component, materials in component_materials.items()\n",
    "    }\n",
    "\n",
    "\n",
    "parsings = []\n",
    "for inp in inputs:\n",
    "    parsing = parse_composition(inp)\n",
    "    parsings.append(parsing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 correct out of 600 (22.00%)\n"
     ]
    }
   ],
   "source": [
    "def performance_report(parsings, outputs):\n",
    "    n_correct = sum(parsing == output for parsing, output in zip(parsings, outputs))\n",
    "    return f\"{n_correct} correct out of {len(parsings)} ({n_correct / len(parsings) * 100:.2f}%)\"\n",
    "\n",
    "print(performance_report(parsings, outputs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: even though this first parser is not great, what would you say are its pros?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ Sidebar: have you noticed the comments under some of the functions? These are [docstrings](https://realpython.com/documenting-python-code/). In particular, these documents are using `>>>`, which is indicative of [doctests](https://docs.python.org/3/library/doctest.html). These are code comments which act as documentation by showing how the function can be used. These lines of code can also be tested, as so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "\n",
    "doctest.testmod()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the command-line, you could also execute these doctests with `pytest`:\n",
    "\n",
    "```sh\n",
    "pytest --doctest-modules\n",
    "```\n",
    "\n",
    "## Looking at false positives\n",
    "\n",
    "Anyway, back to our parsing task. The first thing we should is look at false positives: samples where the parsing was incorrect. The more false positives we look at, the more we'll understand where our parser is going wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è INPUT\n",
      "\n",
      "72%polyamide,19%cotton,9%elastane\n",
      "\n",
      "‚ùå PARSING\n",
      "\n",
      "{\n",
      "    \"\": [\n",
      "        {\n",
      "            \"material\": \"polyamide\",\n",
      "            \"proportion\": 72.0\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "‚úÖ EXPECTED OUTPUT\n",
      "\n",
      "{\n",
      "    \"\": [\n",
      "        {\n",
      "            \"material\": \"polyamide\",\n",
      "            \"proportion\": 72.0\n",
      "        },\n",
      "        {\n",
      "            \"material\": \"cotton\",\n",
      "            \"proportion\": 19.0\n",
      "        },\n",
      "        {\n",
      "            \"material\": \"elastane\",\n",
      "            \"proportion\": 9.0\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "incorrect_parsings = [\n",
    "    (inp, parsing, output)\n",
    "    for inp, parsing, output in zip(inputs, parsings, outputs)\n",
    "    if parsing != output\n",
    "]\n",
    "\n",
    "i = random.randint(0, len(incorrect_parsings))\n",
    "inp, parsing, output = incorrect_parsings[i]\n",
    "print(\"‚¨áÔ∏è INPUT\")\n",
    "print()\n",
    "print(inp)\n",
    "print()\n",
    "print(\"‚ùå PARSING\")\n",
    "print()\n",
    "print(json.dumps(parsing, indent=4, sort_keys=True))\n",
    "print()\n",
    "print(\"‚úÖ EXPECTED OUTPUT\")\n",
    "print()\n",
    "print(json.dumps(output, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the parser\n",
    "\n",
    "After looking at a few cases, it seems that `parse_materials` is only capturing the first material in some cases. This is because it is assuming the materials are separated with a blank space, but doesn't handle commas. Let's fix that. Usually, our code would be in a script, and we would edit it in place. For this tutorial, we'll just copy/paste the `parse_materials` function and edit it here. It's worth spending some time thinking about how you would this set this up for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_materials(text):\n",
    "    material_pat = named_pattern(\"material\", r\"[a-zA-Z√Ä-√ø\\-\\s']+[a-zA-Z√Ä-√ø\\-']\")\n",
    "    proportion_pat = named_pattern(\"proportion\", r\"\\d{1,3}([,\\.]\\d{1,2})?\") + \"%?\"\n",
    "\n",
    "    pattern = sep(rf\"{proportion_pat}\\s*{material_pat}\", \"[,\\s]\")\n",
    "    match = regex.match(pattern, text)\n",
    "\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"material\": m,\n",
    "            \"proportion\": float(p)\n",
    "        }\n",
    "        for m, p in zip(\n",
    "            match.capturesdict()[\"material\"],\n",
    "            match.capturesdict()[\"proportion\"],\n",
    "        )\n",
    "    ]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reparse all the inputs and check the new performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 correct out of 600 (51.00%)\n"
     ]
    }
   ],
   "source": [
    "parsings = []\n",
    "for inp in inputs:\n",
    "    parsing = parse_composition(inp)\n",
    "    parsings.append(parsing)\n",
    "\n",
    "print(performance_report(parsings, outputs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: we reparsed all the inputs, not only the false positives. Why is that important?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing tasks are very common in the data science world. Indeed, a data scientist's job usually starts by ingesting data from several sources. It's often the case that the data is messy and needs scrubbing. Parsing structured data from text is a typical task to perform. Having a good setup where you can change code and get quick feedback about the impact of said change is a game-changer. This is referred to as a \"human-in-the-loop\" setup."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online processing\n",
    "\n",
    "The dataset is quite small, it only contains 600 cases. NLP datasets can be much larger. Let's talk a little bit about we would handle a larger corpus.\n",
    "\n",
    "The first thing we can do is online processing. Our parsing logic is a pure function which doesn't have to be trained on a dataset. In other words, it's unsupervised. What this entails is that the parsing function can be applied to each input individually. In other words, we don't need all the inputs loaded in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 correct out of 600 (51.00%)\n"
     ]
    }
   ],
   "source": [
    "parsings = []\n",
    "\n",
    "with open('shoes/inputs.txt') as inputs:\n",
    "    for inp in inputs:\n",
    "        parsing = parse_composition(inp)\n",
    "        parsings.append(parsing)\n",
    "\n",
    "print(performance_report(parsings, outputs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got exactly the same performance, which is expected. The difference is that we could handle large datasets without clogging the RAM.\n",
    "\n",
    "Actually, our logic could still be improved. What we just did in the previous cell is great in that we read the inputs one by one. However, we are storing the parsings in a list which grows with time. We are also using `outputs`, which is list stored in memory. Ideally, we should be measuring the performance online too.\n",
    "\n",
    "One of the issues with the JSON file format is that it is not made for reading one entry at a time. That's a pretty big con, considering that JSON is ubiquitous in the machine learning world. Thankfully, there are other formats which provide the best of both worlds. For instance, there is the [JSON Lines](https://jsonlines.org/) format, which simply stores each entry in a JSON array on a row.\n",
    "\n",
    "You could say that JSON Lines isn't a new format; it's more of a convention. Nowadays, large NLP datasets are often provided as `.jsonl` files. In our case, we'll have to build that file ourselves. There are Python libraries to make this process easier -- e.g. [`jsonlines`](https://jsonlines.readthedocs.io/en/latest/) -- but it's pretty straightforward to work with without extra dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shoes/outputs.jsonl', 'w') as f:\n",
    "    for output in outputs:\n",
    "        f.write(json.dumps(output) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"lace\": [{\"material\": \"nylon\", \"proportion\": 88.0}, {\"material\": \"spandex\", \"proportion\": 12.0}], \"string\": [{\"material\": \"nylon\", \"proportion\": 88.0}, {\"material\": \"spandex\", \"proportion\": 12.0}], \"top_body\": [{\"material\": \"polyester\", \"proportion\": 100.0}]}\n",
      "{\"\": [{\"material\": \"polyester\", \"proportion\": 92.0}, {\"material\": \"spandex\", \"proportion\": 8.0}]}\n",
      "{\"\": [{\"material\": \"rayon\", \"proportion\": 95.0}, {\"material\": \"spandex\", \"proportion\": 5.0}]}\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 shoes/outputs.jsonl\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can refactor our parsing logic to do everything online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 correct out of 600 (51.00%)\n"
     ]
    }
   ],
   "source": [
    "with (\n",
    "    open('shoes/inputs.txt') as inputs_stream,\n",
    "    open('shoes/outputs.jsonl') as outputs_stream\n",
    "):\n",
    "    n_samples = 0\n",
    "    n_correct = 0\n",
    "    for inp, output in zip(inputs_stream, outputs_stream):\n",
    "        n_samples += 1\n",
    "        output = json.loads(output)\n",
    "        parsing = parse_composition(inp)\n",
    "        n_correct += parsing == output\n",
    "\n",
    "print(f\"{n_correct} correct out of {n_samples} ({n_correct / n_samples * 100:.2f}%)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script consumes the smallest amount of memory possible. The parsing as well as the performance tracking are done online."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: if we wanted to improve our parsing logic, what issue would we now face?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is quite small. Regardless of how we process it, the results can be obtained quite fast. But what if the dataset were much larger? Let's artificially increase the size of the input and output files. We'll do that by processing them several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306000 correct out of 600000 (51.00%)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 0\n",
    "n_correct = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    with (\n",
    "        open('shoes/inputs.txt') as inputs_stream,\n",
    "        open('shoes/outputs.jsonl') as outputs_stream\n",
    "    ):\n",
    "        for inp, output in zip(inputs_stream, outputs_stream):\n",
    "            n_samples += 1\n",
    "            output = json.loads(output)\n",
    "            parsing = parse_composition(inp)\n",
    "            n_correct += parsing == output\n",
    "\n",
    "print(f\"{n_correct} correct out of {n_samples} ({n_correct / n_samples * 100:.2f}%)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's normal that this is taking longer. Processing time should be directly correlated with the amount of data. However, the above case is an illustration of repetitive computation. Each time we loop on a file, we repeat the same computation.\n",
    "\n",
    "A nice trick to know about is caching. The idea is simple: store the output after processing each input, and check if an input has already been processed before processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306000 correct out of 600000 (51.00%)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "@functools.cache\n",
    "def cached_parse_composition(text):\n",
    "    return parse_composition(text)\n",
    "\n",
    "n_samples = 0\n",
    "n_correct = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    with (\n",
    "        open('shoes/inputs.txt') as inputs_stream,\n",
    "        open('shoes/outputs.jsonl') as outputs_stream\n",
    "    ):\n",
    "        for inp, output in zip(inputs_stream, outputs_stream):\n",
    "            n_samples += 1\n",
    "            output = json.loads(output)\n",
    "            parsing = cached_parse_composition(inp)\n",
    "            n_correct += parsing == output\n",
    "\n",
    "print(f\"{n_correct} correct out of {n_samples} ({n_correct / n_samples * 100:.2f}%)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much faster! By default, `functools.cache` caches all the results. However, there are options to set a memory budget if necessary.\n",
    "\n",
    "Caching is one of the oldest tricks in the book: don't repeat what you already know."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON manipulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude this tutorial, let's talk a little about handling JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = json.loads(pathlib.Path('shoes/outputs.json').read_text())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to find the top material for each component. We could do that with some Python logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lace üëâ nylon (82)\n",
      "string üëâ nylon (2)\n",
      "top_body üëâ polyester (5)\n",
      " üëâ polyamide (185)\n",
      "mesh üëâ elastane (42)\n",
      "body_panty üëâ nylon (1)\n",
      "body üëâ spandex (83)\n",
      "fabric üëâ elastane (25)\n",
      "forro üëâ polyester (2)\n",
      "ruffle üëâ polyester (1)\n",
      "elastic üëâ polyester (9)\n",
      "bottom üëâ polyester (8)\n",
      "top üëâ spandex (8)\n",
      "pant üëâ spandex (6)\n",
      "tank üëâ spandex (4)\n",
      "lining üëâ polyester (9)\n",
      "micro üëâ elastane (6)\n",
      "marl_fabric üëâ polyester (1)\n",
      "crochet üëâ polyester (2)\n",
      "liner üëâ polyester (3)\n",
      "panty üëâ nylon (1)\n",
      "edge_lace üëâ nylon (2)\n",
      "centre_front_and_wings üëâ polyamide (1)\n",
      "cup_lining üëâ polyester (2)\n",
      "cup_shell üëâ polyamide (1)\n",
      "back_panel üëâ polyamide (1)\n",
      "front_panel üëâ polyamide (1)\n",
      "cami üëâ polyester (2)\n",
      "short üëâ rayon (2)\n",
      "gusset üëâ cotton (4)\n",
      "g-string üëâ polyamide (6)\n",
      "pants üëâ polyester knitted (1)\n",
      "rib üëâ cotton (3)\n",
      "aol üëâ polyamide (2)\n",
      "shell üëâ polyester (1)\n",
      "ank üëâ rayon (1)\n",
      "knitted_top üëâ cotton woven top (1)\n",
      "trim_lace üëâ polyamide (1)\n",
      "striped_mesh üëâ polyamide (1)\n"
     ]
    }
   ],
   "source": [
    "component_counts = collections.defaultdict(collections.Counter)\n",
    "\n",
    "for output in outputs:\n",
    "    for component, materials in output.items():\n",
    "        for material in materials:\n",
    "            component_counts[component][material['material']] += 1\n",
    "\n",
    "for component, counts in component_counts.items():\n",
    "    material, count = counts.most_common(1)[0]\n",
    "    print(f\"{component} üëâ {material} ({count})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was of doing analysis is very imperative. It's probably easy to follow the logic, but it's not the canonical way of doing data analysis. A good idea is to convert the data to a table, allowing us to use a grammar with which we're more familiar.\n",
    "\n",
    "If you're lucky with the layout of the JSON file, you can use `pd.json_normalize` or `pd.read_json` with default parameters. In our case, we have to a little bit of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>proportion</th>\n",
       "      <th>shoe_id</th>\n",
       "      <th>component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nylon</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spandex</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>lace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nylon</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spandex</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polyester</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>top_body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    material  proportion shoe_id component\n",
       "0      nylon        88.0       0      lace\n",
       "1    spandex        12.0       0      lace\n",
       "2      nylon        88.0       0    string\n",
       "3    spandex        12.0       0    string\n",
       "4  polyester       100.0       0  top_body"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "shoes = pd.json_normalize(\n",
    "    [\n",
    "        {\n",
    "            'shoe_id': i,\n",
    "            'component': component,\n",
    "            'materials': materials\n",
    "        }\n",
    "        for i, output in enumerate(outputs)\n",
    "        for component, materials in output.items()\n",
    "    ],\n",
    "    record_path='materials',\n",
    "    meta=['shoe_id', 'component']\n",
    ")\n",
    "shoes.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do our analysis with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component</th>\n",
       "      <th>material</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>polyamide</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>body</td>\n",
       "      <td>spandex</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>lace</td>\n",
       "      <td>nylon</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>mesh</td>\n",
       "      <td>elastane</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>fabric</td>\n",
       "      <td>elastane</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>elastic</td>\n",
       "      <td>polyester</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>lining</td>\n",
       "      <td>polyester</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bottom</td>\n",
       "      <td>polyester</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>top</td>\n",
       "      <td>spandex</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>g-string</td>\n",
       "      <td>polyamide</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pant</td>\n",
       "      <td>rayon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>micro</td>\n",
       "      <td>elastane</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>top_body</td>\n",
       "      <td>polyester</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>gusset</td>\n",
       "      <td>cotton</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tank</td>\n",
       "      <td>spandex</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rib</td>\n",
       "      <td>elastane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>liner</td>\n",
       "      <td>polyester</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>short</td>\n",
       "      <td>spandex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>string</td>\n",
       "      <td>spandex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>forro</td>\n",
       "      <td>polyester</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>crochet</td>\n",
       "      <td>elastane</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cami</td>\n",
       "      <td>spandex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>cup_lining</td>\n",
       "      <td>polyester</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aol</td>\n",
       "      <td>polyamide</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>edge_lace</td>\n",
       "      <td>nylon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>shell</td>\n",
       "      <td>polyester</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>back_panel</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ruffle</td>\n",
       "      <td>polyester</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>front_panel</td>\n",
       "      <td>polyamide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ank</td>\n",
       "      <td>spandex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>striped_mesh</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>pants</td>\n",
       "      <td>polyester knitted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>trim_lace</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>panty</td>\n",
       "      <td>nylon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>knitted_top</td>\n",
       "      <td>cotton woven top</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>cup_shell</td>\n",
       "      <td>polyamide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>marl_fabric</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>centre_front_and_wings</td>\n",
       "      <td>polyamide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>body_panty</td>\n",
       "      <td>spandex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  component           material  count\n",
       "9                                    polyamide    185\n",
       "35                     body            spandex     83\n",
       "75                     lace              nylon     82\n",
       "89                     mesh           elastane     42\n",
       "56                   fabric           elastane     25\n",
       "55                  elastic          polyester      9\n",
       "84                   lining          polyester      9\n",
       "39                   bottom          polyester      8\n",
       "121                     top            spandex      8\n",
       "68                 g-string          polyamide      6\n",
       "100                    pant              rayon      6\n",
       "95                    micro           elastane      6\n",
       "122                top_body          polyester      5\n",
       "70                   gusset             cotton      4\n",
       "117                    tank            spandex      4\n",
       "105                     rib           elastane      3\n",
       "82                    liner          polyester      3\n",
       "110                   short            spandex      2\n",
       "112                  string            spandex      2\n",
       "63                    forro          polyester      2\n",
       "46                  crochet           elastane      2\n",
       "43                     cami            spandex      2\n",
       "48               cup_lining          polyester      2\n",
       "22                      aol          polyamide      2\n",
       "51                edge_lace              nylon      2\n",
       "107                   shell          polyester      1\n",
       "23               back_panel           elastane      1\n",
       "106                  ruffle          polyester      1\n",
       "65              front_panel          polyamide      1\n",
       "20                      ank            spandex      1\n",
       "113            striped_mesh           elastane      1\n",
       "102                   pants  polyester knitted      1\n",
       "124               trim_lace           elastane      1\n",
       "103                   panty              nylon      1\n",
       "71              knitted_top   cotton woven top      1\n",
       "50                cup_shell          polyamide      1\n",
       "86              marl_fabric           elastane      1\n",
       "45   centre_front_and_wings          polyamide      1\n",
       "37               body_panty            spandex      1"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    shoes\n",
    "    .groupby(['component', 'material'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    "    .groupby('component')\n",
    "    .head(1)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: can you think of another possible analysis?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON manipulation with SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using [SQLite](https://www.sqlite.org/index.html). It is available by default with Python.\n",
    "\n",
    "First, we'll write a script to upload the data to SQLite. The database will be running in memory, which is one of the abilities of SQLite that other databases don't have. It's why SQLite is used in mobile phone apps.\n",
    "\n",
    "Typically, you won't have to write this kind of code. As a data scientist, you will mostly be working on databases where the data has already been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Remove a file (same as remove()).\n",
      "\n",
      "If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "  and path should be relative; path will then be relative to that directory.\n",
      "dir_fd may not be implemented on your platform.\n",
      "  If it is unavailable, using it will raise a NotImplementedError.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "?os.unlink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sqlite3\n",
    "\n",
    "pathlib.Path('shoes.db').unlink(missing_ok=True)\n",
    "conn = sqlite3.connect('shoes.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS shoes (composition TEXT)')\n",
    "\n",
    "for i, output in enumerate(outputs):\n",
    "    payload = json.dumps([\n",
    "        {\n",
    "            'shoe_id': i,\n",
    "            'component': component,\n",
    "            'materials': materials\n",
    "        }\n",
    "        for component, materials in output.items()\n",
    "    ])\n",
    "    cursor.execute('INSERT INTO shoes VALUES (?)', [payload])\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table can now be queried with `pandas.read_sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"shoe_id\": 0, \"component\": \"lace\", \"material...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"shoe_id\": 1, \"component\": \"\", \"materials\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"shoe_id\": 2, \"component\": \"\", \"materials\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"shoe_id\": 3, \"component\": \"\", \"materials\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"shoe_id\": 4, \"component\": \"lace\", \"material...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         composition\n",
       "0  [{\"shoe_id\": 0, \"component\": \"lace\", \"material...\n",
       "1  [{\"shoe_id\": 1, \"component\": \"\", \"materials\": ...\n",
       "2  [{\"shoe_id\": 2, \"component\": \"\", \"materials\": ...\n",
       "3  [{\"shoe_id\": 3, \"component\": \"\", \"materials\": ...\n",
       "4  [{\"shoe_id\": 4, \"component\": \"lace\", \"material..."
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM shoes\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('shoes.db')\n",
    "pd.read_sql(query, conn).head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: why do we have to recreate a connection?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write a SQL query to normalize the JSON. We're using SQLite, which has a `JSON_TREE` function to flatten any JSON object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shoe_id</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>component_number</th>\n",
       "      <th>material_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>shoe_id</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>component</td>\n",
       "      <td>lace</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>material</td>\n",
       "      <td>nylon</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>proportion</td>\n",
       "      <td>88.0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>material</td>\n",
       "      <td>spandex</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>proportion</td>\n",
       "      <td>12.0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>shoe_id</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>component</td>\n",
       "      <td>string</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>material</td>\n",
       "      <td>nylon</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>proportion</td>\n",
       "      <td>88.0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>material</td>\n",
       "      <td>spandex</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>proportion</td>\n",
       "      <td>12.0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>shoe_id</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>component</td>\n",
       "      <td>top_body</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>material</td>\n",
       "      <td>polyester</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>proportion</td>\n",
       "      <td>100.0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>shoe_id</td>\n",
       "      <td>1</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>component</td>\n",
       "      <td></td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>material</td>\n",
       "      <td>polyester</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>proportion</td>\n",
       "      <td>92.0</td>\n",
       "      <td>818</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shoe_id         key      value  component_number  material_number\n",
       "0         0     shoe_id          0               818             1854\n",
       "1         0   component       lace               818             1854\n",
       "2         0    material      nylon               818             1854\n",
       "3         0  proportion       88.0               818             1854\n",
       "4         0    material    spandex               818             1854\n",
       "5         0  proportion       12.0               818             1854\n",
       "6         0     shoe_id          0               818             1854\n",
       "7         0   component     string               818             1854\n",
       "8         0    material      nylon               818             1854\n",
       "9         0  proportion       88.0               818             1854\n",
       "10        0    material    spandex               818             1854\n",
       "11        0  proportion       12.0               818             1854\n",
       "12        0     shoe_id          0               818             1854\n",
       "13        0   component   top_body               818             1854\n",
       "14        0    material  polyester               818             1854\n",
       "15        0  proportion      100.0               818             1854\n",
       "16        1     shoe_id          1               818             1854\n",
       "17        1   component                          818             1854\n",
       "18        1    material  polyester               818             1854\n",
       "19        1  proportion       92.0               818             1854"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH elements AS (\n",
    "    SELECT\n",
    "        shoes.rowid - 1 AS shoe_id,\n",
    "        key,\n",
    "        value,\n",
    "        SUM(CASE WHEN key = 'component' THEN 1 ELSE 0 END) OVER () AS component_number,\n",
    "        SUM(CASE WHEN key = 'material' THEN 1 ELSE 0 END) OVER () AS material_number\n",
    "    FROM\n",
    "        shoes,\n",
    "        JSON_TREE(JSON(composition))\n",
    "    WHERE JSON_TREE.TYPE NOT IN ('object', 'array')\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM elements\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn).head(20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves of the rules of tidy data:\n",
    "\n",
    "1. Each variable must have its own column\n",
    "2. Each observation must have its own row\n",
    "3. Each value must have its own cell\n",
    "\n",
    "What would be an observation be in this case? Usually, the observation is the most atomic element. In a case of a shoe, so the most atomic element is the material.\n",
    "\n",
    "We have a bit of SQL/JSON karate to do ü•ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shoe_id</th>\n",
       "      <th>component</th>\n",
       "      <th>material</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lace</td>\n",
       "      <td>nylon</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lace</td>\n",
       "      <td>spandex</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>string</td>\n",
       "      <td>nylon</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>string</td>\n",
       "      <td>spandex</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>top_body</td>\n",
       "      <td>polyester</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>polyester</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>spandex</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>rayon</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>spandex</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>nylon</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shoe_id component   material  proportion\n",
       "0        0      lace      nylon        88.0\n",
       "1        0      lace    spandex        12.0\n",
       "2        0    string      nylon        88.0\n",
       "3        0    string    spandex        12.0\n",
       "4        0  top_body  polyester       100.0\n",
       "5        1            polyester        92.0\n",
       "6        1              spandex         8.0\n",
       "7        2                rayon        95.0\n",
       "8        2              spandex         5.0\n",
       "9        3                nylon        87.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH elements AS (\n",
    "    SELECT\n",
    "        shoes.rowid - 1 AS shoe_id,\n",
    "        key,\n",
    "        value,\n",
    "        SUM(CASE WHEN key = 'component' THEN 1 ELSE 0 END) OVER (\n",
    "            PARTITION BY shoes.rowid\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS component_number,\n",
    "        SUM(CASE WHEN key = 'material' THEN 1 ELSE 0 END) OVER (\n",
    "            PARTITION BY shoes.rowid\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS material_number\n",
    "    FROM\n",
    "        shoes,\n",
    "        JSON_TREE(JSON(composition))\n",
    "    WHERE JSON_TREE.TYPE NOT IN ('object', 'array')\n",
    "),\n",
    "\n",
    "components AS (\n",
    "    SELECT\n",
    "        shoe_id,\n",
    "        component_number,\n",
    "        value AS component\n",
    "    FROM elements\n",
    "    WHERE key = 'component'\n",
    "),\n",
    "\n",
    "materials AS (\n",
    "    SELECT\n",
    "        shoe_id,\n",
    "        component_number,\n",
    "        material_number,\n",
    "        value AS material\n",
    "    FROM elements\n",
    "    WHERE key = 'material'\n",
    "),\n",
    "\n",
    "proportions AS (\n",
    "    SELECT\n",
    "        shoe_id,\n",
    "        component_number,\n",
    "        material_number,\n",
    "        CAST(value AS REAL) AS proportion\n",
    "    FROM elements\n",
    "    WHERE key = 'proportion'\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    materials.shoe_id,\n",
    "    components.component,\n",
    "    materials.material,\n",
    "    proportions.proportion\n",
    "FROM materials\n",
    "LEFT JOIN components USING (shoe_id, component_number)\n",
    "LEFT JOIN proportions USING (shoe_id, component_number, material_number)\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn).head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: how can we check whether this SQL query is actually correct?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store all this result into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS materials AS\n",
    "    WITH elements AS (\n",
    "        SELECT\n",
    "            shoes.rowid - 1 AS shoe_id,\n",
    "            key,\n",
    "            value,\n",
    "            SUM(CASE WHEN key = 'component' THEN 1 ELSE 0 END) OVER (\n",
    "                PARTITION BY shoes.rowid\n",
    "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "            ) AS component_number,\n",
    "            SUM(CASE WHEN key = 'material' THEN 1 ELSE 0 END) OVER (\n",
    "                PARTITION BY shoes.rowid\n",
    "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "            ) AS material_number\n",
    "        FROM\n",
    "            shoes,\n",
    "            JSON_TREE(JSON(composition))\n",
    "        WHERE JSON_TREE.TYPE NOT IN ('object', 'array')\n",
    "    ),\n",
    "\n",
    "    components AS (\n",
    "        SELECT\n",
    "            shoe_id,\n",
    "            component_number,\n",
    "            value AS component\n",
    "        FROM elements\n",
    "        WHERE key = 'component'\n",
    "    ),\n",
    "\n",
    "    materials AS (\n",
    "        SELECT\n",
    "            shoe_id,\n",
    "            component_number,\n",
    "            material_number,\n",
    "            value AS material\n",
    "        FROM elements\n",
    "        WHERE key = 'material'\n",
    "    ),\n",
    "\n",
    "    proportions AS (\n",
    "        SELECT\n",
    "            shoe_id,\n",
    "            component_number,\n",
    "            material_number,\n",
    "            CAST(value AS REAL) AS proportion\n",
    "        FROM elements\n",
    "        WHERE key = 'proportion'\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        materials.shoe_id,\n",
    "        components.component,\n",
    "        materials.material,\n",
    "        proportions.proportion\n",
    "    FROM materials\n",
    "    JOIN components USING (shoe_id, component_number)\n",
    "    JOIN proportions USING (shoe_id, component_number, material_number)\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('shoes.db')\n",
    "conn.execute(query)\n",
    "conn.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query the table and do our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component</th>\n",
       "      <th>material</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>polyamide</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body</td>\n",
       "      <td>spandex</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lace</td>\n",
       "      <td>nylon</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mesh</td>\n",
       "      <td>elastane</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fabric</td>\n",
       "      <td>elastane</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>elastic</td>\n",
       "      <td>elastane</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lining</td>\n",
       "      <td>polyester</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bottom</td>\n",
       "      <td>polyester</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>top</td>\n",
       "      <td>spandex</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g-string</td>\n",
       "      <td>cotton</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>micro</td>\n",
       "      <td>elastane</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pant</td>\n",
       "      <td>rayon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>top_body</td>\n",
       "      <td>polyester</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gusset</td>\n",
       "      <td>cotton</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tank</td>\n",
       "      <td>spandex</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>liner</td>\n",
       "      <td>polyester</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rib</td>\n",
       "      <td>cotton</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aol</td>\n",
       "      <td>elastane</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cami</td>\n",
       "      <td>polyester</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>crochet</td>\n",
       "      <td>elastane</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cup_lining</td>\n",
       "      <td>polyester</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>edge_lace</td>\n",
       "      <td>nylon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>forro</td>\n",
       "      <td>polyester</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>short</td>\n",
       "      <td>rayon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>string</td>\n",
       "      <td>nylon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ank</td>\n",
       "      <td>rayon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>back_panel</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>body_panty</td>\n",
       "      <td>nylon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>centre_front_and_wings</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cup_shell</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>front_panel</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>knitted_top</td>\n",
       "      <td>cotton woven top</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>marl_fabric</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pants</td>\n",
       "      <td>polyester knitted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>panty</td>\n",
       "      <td>nylon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ruffle</td>\n",
       "      <td>polyester</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>shell</td>\n",
       "      <td>polyester</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>striped_mesh</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>trim_lace</td>\n",
       "      <td>elastane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 component           material    n\n",
       "0                                   polyamide  185\n",
       "1                     body            spandex   83\n",
       "2                     lace              nylon   82\n",
       "3                     mesh           elastane   42\n",
       "4                   fabric           elastane   25\n",
       "5                  elastic           elastane    9\n",
       "6                   lining          polyester    9\n",
       "7                   bottom          polyester    8\n",
       "8                      top            spandex    8\n",
       "9                 g-string             cotton    6\n",
       "10                   micro           elastane    6\n",
       "11                    pant              rayon    6\n",
       "12                top_body          polyester    5\n",
       "13                  gusset             cotton    4\n",
       "14                    tank            spandex    4\n",
       "15                   liner          polyester    3\n",
       "16                     rib             cotton    3\n",
       "17                     aol           elastane    2\n",
       "18                    cami          polyester    2\n",
       "19                 crochet           elastane    2\n",
       "20              cup_lining          polyester    2\n",
       "21               edge_lace              nylon    2\n",
       "22                   forro          polyester    2\n",
       "23                   short              rayon    2\n",
       "24                  string              nylon    2\n",
       "25                     ank              rayon    1\n",
       "26              back_panel           elastane    1\n",
       "27              body_panty              nylon    1\n",
       "28  centre_front_and_wings           elastane    1\n",
       "29               cup_shell           elastane    1\n",
       "30             front_panel           elastane    1\n",
       "31             knitted_top   cotton woven top    1\n",
       "32             marl_fabric           elastane    1\n",
       "33                   pants  polyester knitted    1\n",
       "34                   panty              nylon    1\n",
       "35                  ruffle          polyester    1\n",
       "36                   shell          polyester    1\n",
       "37            striped_mesh           elastane    1\n",
       "38               trim_lace           elastane    1"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    DISTINCT component,\n",
    "    FIRST_VALUE(material) OVER (\n",
    "        PARTITION BY component\n",
    "        ORDER BY n DESC\n",
    "    ) AS material,\n",
    "    FIRST_VALUE(n) OVER (\n",
    "        PARTITION BY component\n",
    "        ORDER BY n DESC\n",
    "    ) AS n\n",
    "FROM (\n",
    "    SELECT\n",
    "        component,\n",
    "        material,\n",
    "        COUNT(*) AS n\n",
    "    FROM materials\n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "ORDER BY n DESC\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Question: what could have been an alternative approach for analysing the data with SQL? Did we have to write so much SQL?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55fbbcf542e06cc59ad76a1e0d5dc36ee204d6d2b704491656ee6b3487310122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
